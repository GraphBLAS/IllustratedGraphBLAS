{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Sparse Neural Networks\n",
    "\n",
    "Forward propagation through sparse weight matrices using GraphBLAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphblas as gb\n",
    "from graphblas import Matrix, Vector, semiring, binary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense vs Sparse Weights\n",
    "\n",
    "Many neural network weights are near-zero and can be pruned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated dense weights with many small values\n",
    "np.random.seed(42)\n",
    "dense_weights = np.random.randn(6, 4) * 0.5\n",
    "dense_weights[np.abs(dense_weights) < 0.3] = 0  # Prune small weights\n",
    "\n",
    "print(\"Dense weight matrix (zeros shown):\")\n",
    "print(np.round(dense_weights, 2))\n",
    "print(f\"\\nNon-zero elements: {np.count_nonzero(dense_weights)} / {dense_weights.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to sparse GraphBLAS matrix\n",
    "rows, cols = np.nonzero(dense_weights)\n",
    "vals = dense_weights[rows, cols]\n",
    "\n",
    "W = Matrix.from_coo(rows.tolist(), cols.tolist(), vals.tolist(), \n",
    "                    nrows=6, ncols=4, dtype=float)\n",
    "print(\"Sparse weight matrix:\")\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass: x × W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input vector (sparse: only some features active)\n",
    "x = Vector.from_coo([0, 2, 5], [1.0, 0.5, -0.8], size=6, dtype=float)\n",
    "print(\"Sparse input x:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass: y = x × W (vector-matrix multiply)\n",
    "y = x.vxm(W, semiring.plus_times).new()\n",
    "print(\"Output y = x × W:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU: max(0, x)\n",
    "def relu(v):\n",
    "    return v.select(\">\", 0).new()\n",
    "\n",
    "y_relu = relu(y)\n",
    "print(\"After ReLU:\")\n",
    "print(y_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold activation (binary)\n",
    "def threshold(v, t=0.0):\n",
    "    return v.select(\">\", t).apply(binary.pair).new(dtype=bool)\n",
    "\n",
    "y_thresh = threshold(y, 0.0)\n",
    "print(\"After threshold (> 0):\")\n",
    "print(y_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2-layer network: 6 -> 4 -> 2\n",
    "np.random.seed(123)\n",
    "\n",
    "# Layer 1: 6 inputs -> 4 hidden\n",
    "w1_dense = np.random.randn(6, 4) * 0.5\n",
    "w1_dense[np.abs(w1_dense) < 0.4] = 0\n",
    "r, c = np.nonzero(w1_dense)\n",
    "W1 = Matrix.from_coo(r.tolist(), c.tolist(), w1_dense[r, c].tolist(),\n",
    "                     nrows=6, ncols=4, dtype=float)\n",
    "\n",
    "# Layer 2: 4 hidden -> 2 outputs\n",
    "w2_dense = np.random.randn(4, 2) * 0.5\n",
    "w2_dense[np.abs(w2_dense) < 0.3] = 0\n",
    "r, c = np.nonzero(w2_dense)\n",
    "W2 = Matrix.from_coo(r.tolist(), c.tolist(), w2_dense[r, c].tolist(),\n",
    "                     nrows=4, ncols=2, dtype=float)\n",
    "\n",
    "print(\"W1 (6x4):\")\n",
    "print(W1)\n",
    "print(\"\\nW2 (4x2):\")\n",
    "print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass through both layers\n",
    "x = Vector.from_coo([0, 3, 5], [1.0, -0.5, 0.8], size=6, dtype=float)\n",
    "print(\"Input:\")\n",
    "print(x)\n",
    "\n",
    "# Layer 1 + ReLU\n",
    "h = relu(x.vxm(W1, semiring.plus_times).new())\n",
    "print(\"\\nHidden (after ReLU):\")\n",
    "print(h)\n",
    "\n",
    "# Layer 2\n",
    "output = h.vxm(W2, semiring.plus_times).new()\n",
    "print(\"\\nOutput:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Dense weights\n",
    "axes[0].imshow(np.abs(w1_dense), cmap='Blues')\n",
    "axes[0].set_title('Layer 1 Weights (magnitude)')\n",
    "axes[0].set_xlabel('Output neurons')\n",
    "axes[0].set_ylabel('Input neurons')\n",
    "\n",
    "# Sparse pattern\n",
    "sparse_pattern = (np.abs(w1_dense) > 0).astype(int)\n",
    "axes[1].imshow(sparse_pattern, cmap='binary')\n",
    "axes[1].set_title('Sparsity Pattern (black = non-zero)')\n",
    "axes[1].set_xlabel('Output neurons')\n",
    "axes[1].set_ylabel('Input neurons')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sparsity = 1 - np.count_nonzero(w1_dense) / w1_dense.size\n",
    "print(f\"Sparsity: {sparsity:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
